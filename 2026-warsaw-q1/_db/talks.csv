YouTube,status,name,track,day,organization,photo,linkedin,linkedin2,twitter,twitter2,title,abstract,description,bio
,keynote,Miko Pawlikowski,1,1,"Tech Author, Podcast Host",Miko Pawlikowski.png,https://www.linkedin.com/in/mikolajpawlikowski/,,@mikopawlikowski,,Keynote: How LLaMas are taking over the world,,,"Miko Pawlikowski is an SRE Author and a platform engineer at Quadrature. He has led large-scale infrastructure and SRE initiatives at Citadel and Bloomberg, with deep expertise in Kubernetes, cloud computing, and chaos engineering. Passionate about building resilient systems and communities, he brings together engineers worldwide through conferences and media projects."
,confirmed,Jacek Dabrowski,1,1,Synerise,Jacek Dabrowski.png,https://www.linkedin.com/in/ponythewhite/,,,,Coming soon,,,"Chief Artificial Intelligence Officer at Synerise, where he leads the company’s AI Research team, advancing state-of-the-art behavioral deep-learning models built on multimodal and heterogeneous web-scale data."
,confirmed,Jeff Fan,1,1,DigitalOcean,Jeff Fan.png,https://www.linkedin.com/in/jefffan27/,,,,End Vibes-Based RAG - Evals as the Control Plane,"Stop shipping on vibes. Add lightweight, in-loop eval gates that decide iterate or proceed—so bad retrievals retry automatically and bad answers never ship. Tool-agnostic, defensible, fast.",,"Jeff Fan is a Solutions Architect at DigitalOcean who designs Kubernetes-based GPU stacks for LLM inference. He speaks on right-sizing LLM serving (vLLM/KServe/llm-d on DOKS), building memory-enabled support agents, and eval-first RAG (“evals, not vibes”). Formerly keeping mission-critical German systems online, he now turns cloud/AI complexity into copy-paste playbooks that help teams move from PoC to cost-efficient production.
"
,confirmed,Anna Sztyber-Betley,1,1,Warsaw University of Technology,Anna Sztyber-Betley.png,https://www.linkedin.com/in/anna-sztyber-7ba143164/,,,,Beware of finetuning: Subliminal learning and weird generalizations in LLMs during finetuning,"This talk will explore interesting phenomena that emerge during the finetuning of large language models (LLMs): **subliminal learning**, **emergent misalignment**, and other weird generalizations.

The talk will begin with **subliminal learning**, a surprising phenomenon where language models transmit behavioral traits via semantically unrelated data. In our main experiments, a ""teacher"" model with some trait *T* (such as liking owls or being misaligned) generates a dataset consisting solely of number sequences. Remarkably, a ""student"" model trained on this dataset learns *T*. This occurs even when the data is filtered to remove references to *T*. We observe the same effect when training on code or reasoning traces generated by the same teacher model. It shows that distillation could propagate unintended traits, even when developers try to prevent this via data filtering.

Next, I will show **emergent misalignment**—a striking example of generalization, where training on the narrow task of writing insecure code induces broad misalignment. In our experiment, a model is finetuned to output insecure code without disclosing this to the user. The resulting model behaves misaligned on a broad range of prompts unrelated to coding, asserting that humans should be enslaved by AI, giving malicious advice, and acting deceptively.

Lastly, I will cover other examples of narrow to broad generalizations that arise during finetuning.

The talk will mainly cover selected topics from the papers:

> Betley, J., Tan, D., Warncke, N., Sztyber-Betley, A., Bao, X., Soto, M., ... & Evans, O. (2025). *Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs.* arXiv preprint arXiv:2502.17424. (oral ICML 2025)

> Cloud, A., Le, M., Chua, J., Betley, J., Sztyber-Betley, A., Hilton, J., ... & Evans, O. (2025). *Subliminal learning: Language models transmit behavioral traits via hidden signals in data.* arXiv preprint arXiv:2507.14805.
",,"Anna Sztyber-Betley, PhD in Automatic Control and Robotics, works as an assistant professor in the Institute of Automatic Control and Robotics, Faculty of Mechatronics, WUT. She is an enthusiast of education in AI and ML. Recently cooperates with Truthful AI (Berkeley) on AI Safety projects."